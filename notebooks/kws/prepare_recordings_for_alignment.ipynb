{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d171f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympi import *\n",
    "import torchaudio\n",
    "from glob import glob\n",
    "import os\n",
    "os.chdir(r'C:\\projects\\malachor5')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(r'C:\\projects\\malachor5\\scripts')\n",
    "from string_norm import tira2arpabet, tira2mfa, remove_punct\n",
    "from lid_utils import is_tira_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d85b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HH20210312': {'eaf': 'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20210312.eaf',\n",
       "  'wav': 'E:\\\\data\\\\wav\\\\HH20210312.WAV'},\n",
       " 'HH20210913': {'eaf': 'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20210913.eaf',\n",
       "  'wav': 'E:\\\\data\\\\wav\\\\HH20210913.wav'},\n",
       " 'HH20220327-2': {'eaf': 'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20220327-2.eaf',\n",
       "  'wav': 'E:\\\\data\\\\wav\\\\HH20220327-2.wav'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eaf_paths = glob(r'C:\\projects\\malachor5\\meta\\*.eaf')\n",
    "wav_paths = glob(r'E:\\data\\wav\\*.wav')\n",
    "speaker_tiers = ['SHA', 'NIN', 'HIM', 'MAR', 'PET', 'MISC']\n",
    "stem2paths={}\n",
    "for eaf_path in eaf_paths:\n",
    "    basename = os.path.basename(eaf_path)\n",
    "    stem = os.path.splitext(basename)[0]\n",
    "    wav_path = [wav_path for wav_path in wav_paths if stem in wav_path]\n",
    "    assert len(wav_path)==1\n",
    "    wav_path=wav_path[0]\n",
    "    stem2paths[stem]={'eaf': eaf_path, 'wav': wav_path}\n",
    "stem2paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722161f",
   "metadata": {},
   "source": [
    "# Merge tiers\n",
    "`IPA Transcription` kept separate from `HIM`: add annotations back in where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de7c457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\malachor5\\meta\\HH20210312.eaf\n",
      "add_count=0\tskip_count=246\n",
      "C:\\projects\\malachor5\\meta\\HH20210913.eaf\n",
      "add_count=0\tskip_count=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\malachor5\\meta\\HH20220327-2.eaf\n",
      "add_count=0\tskip_count=89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for eaf_path in tqdm(eaf_paths):\n",
    "    tqdm.write(eaf_path)\n",
    "    eaf = Elan.Eaf(eaf_path)\n",
    "    ipa_tier = 'IPA Transcription'\n",
    "    himidan_tier = 'HIM'\n",
    "    if ipa_tier not in eaf.get_tier_names():\n",
    "        tqdm.write('IPA transcription tier not found, skipping...')\n",
    "        continue\n",
    "    add_count=0\n",
    "    skip_count=0\n",
    "    for interval in eaf.get_annotation_data_for_tier(ipa_tier):\n",
    "        start, end, value = interval[:3]\n",
    "        midpoint = (start+end)//2\n",
    "        if eaf.get_annotation_data_at_time(himidan_tier, midpoint):\n",
    "            skip_count+=1\n",
    "            continue\n",
    "        eaf.add_annotation(himidan_tier, start, end, value)\n",
    "        add_count+=1\n",
    "    print(f\"{add_count=}\\t{skip_count=}\")\n",
    "    eaf.to_file(eaf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff86368",
   "metadata": {},
   "source": [
    "# Remove non-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2304a58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\malachor5\\meta\\HH20210312.eaf\n",
      "tier='NIN'\tremove_count=15\n",
      "tier='HIM'\tremove_count=32\n",
      "tier='PET'\tremove_count=14\n",
      "tier='MISC'\tremove_count=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\malachor5\\meta\\HH20210913.eaf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tier='HIM'\tremove_count=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\malachor5\\meta\\HH20220327-2.eaf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tier='HIM'\tremove_count=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for eaf_path in tqdm(eaf_paths):\n",
    "    tqdm.write(eaf_path)\n",
    "    eaf = Elan.Eaf(eaf_path)\n",
    "    for i, tier in enumerate(speaker_tiers):\n",
    "        remove_count = 0\n",
    "        if tier not in eaf.get_tier_names():\n",
    "            continue\n",
    "        for interval in eaf.get_annotation_data_for_tier(tier):\n",
    "            start, end, value = interval[:3]\n",
    "            midpoint = (start+end)//2\n",
    "            # remove empty or non-speech tiers\n",
    "            if (not value) or (value in ['HUMMING', 'NOLING']):\n",
    "                eaf.remove_annotation(tier, midpoint)\n",
    "                remove_count+=1\n",
    "        if remove_count:\n",
    "            tqdm.write(f\"{tier=}\\t{remove_count=}\")\n",
    "    eaf.to_file(eaf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d3ddf",
   "metadata": {},
   "source": [
    "# Overlap\n",
    "Let's figure out how many overlapping intervals there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "372402bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\malachor5\\meta\\HH20210312.eaf\n",
      "1    0.968445\n",
      "0    0.611428\n",
      "2    0.031555\n",
      "Name: count, dtype: float64\n",
      "C:\\projects\\malachor5\\meta\\HH20210913.eaf\n",
      "0    1.964611\n",
      "1    0.955809\n",
      "2    0.044191\n",
      "Name: count, dtype: float64\n",
      "C:\\projects\\malachor5\\meta\\HH20220327-2.eaf\n",
      "1    0.963585\n",
      "0    0.527386\n",
      "2    0.036415\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for eaf_path in eaf_paths:\n",
    "    print(eaf_path)\n",
    "    eaf = Elan.Eaf(eaf_path)\n",
    "    maxlen = eaf.get_full_time_interval()[1]\n",
    "    overlap_array = np.zeros(maxlen, dtype=int)\n",
    "    for i, tier in enumerate(speaker_tiers):\n",
    "        if tier not in eaf.get_tier_names():\n",
    "            continue\n",
    "        for interval in eaf.get_annotation_data_for_tier(tier):\n",
    "            start, end = interval[:2]\n",
    "            overlap_array[start:end]+=1\n",
    "    overlap_array = pd.Series(overlap_array)\n",
    "    print(overlap_array.value_counts()/(overlap_array>0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95528f4",
   "metadata": {},
   "source": [
    "3-4% overlap for each file\n",
    "\n",
    "# Create corpus for alignment\n",
    "Next step, let's save all intervals as separate .wav and .lab files in a directory structure expected by MFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "777cf290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 29.13it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1999.83it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1997.60it/s]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# data_dir = r'C:\\projects\\malachor5\\data\\tira_eval_mfa'\n",
    "# for filestem, paths in tqdm(stem2paths.items()):\n",
    "#     wav, sr = torchaudio.load(paths['wav'])\n",
    "#     samples_per_ms = sr/1_000\n",
    "#     eaf = Elan.Eaf(paths['eaf'])\n",
    "#     for speaker in tqdm(speaker_tiers):\n",
    "#         if speaker not in eaf.get_tier_names():\n",
    "#             continue\n",
    "#         speaker_dir = os.path.join(data_dir, speaker)\n",
    "#         os.makedirs(speaker_dir, exist_ok=True)\n",
    "#         for interval in eaf.get_annotation_data_for_tier(speaker):\n",
    "#             start_ms, end_ms, value = interval[:3]\n",
    "#             start_samples = int(start_ms*samples_per_ms)\n",
    "#             end_samples = int(end_ms*samples_per_ms)\n",
    "#             clip_stem = f\"{filestem}_{start_ms}_{end_ms}\"\n",
    "#             clip_path = os.path.join(speaker_dir, clip_stem)\n",
    "\n",
    "#             # save .wav\n",
    "#             wav_clip = wav[:,start_samples:end_samples]\n",
    "#             torchaudio.save(clip_path+'.wav', wav_clip, sr)\n",
    "\n",
    "#             # save .lab\n",
    "#             # with open(clip_path+'.lab', 'w', encoding='utf8') as f:\n",
    "#                 # f.write(value)\n",
    "\n",
    "#             # save .TextGrid\n",
    "#             duration_s = (end_ms-start_ms)/1_000\n",
    "#             textgrid = Praat.TextGrid(xmin=0, xmax=duration_s)\n",
    "#             label_tier: Praat.Tier = textgrid.add_tier('label')\n",
    "#             label_tier.add_interval(0, duration_s, value)\n",
    "#             textgrid.to_file(clip_path+'.TextGrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f72c23",
   "metadata": {},
   "source": [
    "Except! That isn't necessary, just convert each `.eaf` file into a TextGrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1247edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:15<00:00,  5.33s/it]\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'C:\\projects\\malachor5\\data\\tira_eval_mfa'\n",
    "for filestem, paths in tqdm(stem2paths.items()):\n",
    "    wav, sr = torchaudio.load(paths['wav'])\n",
    "    eaf = Elan.Eaf(paths['eaf'])\n",
    "\n",
    "    out_stem = os.path.join(data_dir, filestem)\n",
    "\n",
    "    tg = eaf.to_textgrid(filtin=speaker_tiers)\n",
    "    tg.to_file(out_stem+'.TextGrid')\n",
    "\n",
    "    torchaudio.save(out_stem+'.wav', wav, sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3904332",
   "metadata": {},
   "source": [
    "# Dictionary\n",
    "Save arpabet and MFA dictionaries for Tira words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2bb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 10.48it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  9.16it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  6.71it/s]\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(214,\n",
       " {'a',\n",
       "  'àlɔ́',\n",
       "  'àn',\n",
       "  'àpɾì',\n",
       "  'àpɾí',\n",
       "  'àŋgèɲɔ́',\n",
       "  'àɾò',\n",
       "  'á',\n",
       "  'ápɾí',\n",
       "  'âɾò',\n",
       "  'cìcə̀lò',\n",
       "  'cícə̀lò',\n",
       "  'cùbò',\n",
       "  'cùbó',\n",
       "  'cùbɔ̀',\n",
       "  'cɔ́lɔ̀',\n",
       "  'cə̀mú',\n",
       "  'dɔ̀ɽðàt̪à',\n",
       "  'dɔ́ɽðàt̪à',\n",
       "  'dɔ́ɾàt̪à',\n",
       "  'emakəŋe',\n",
       "  'éɲá',\n",
       "  'gèɲɔ́',\n",
       "  'giɲ',\n",
       "  'gìɲɔ́',\n",
       "  'i',\n",
       "  'ìjɔ́',\n",
       "  'íbí',\n",
       "  'jál',\n",
       "  'jáŋál',\n",
       "  'jáŋə́l',\n",
       "  'jéɲál',\n",
       "  'jìgèɲɔ́',\n",
       "  'jə',\n",
       "  'jɛ',\n",
       "  'jɛ̀',\n",
       "  'kà',\n",
       "  'kàŋú',\n",
       "  'kàɾɛ́',\n",
       "  'ká',\n",
       "  'káddɔ̀ɽðàt̪à',\n",
       "  'kádɔ̀ɽðàt̪à',\n",
       "  'kágɛ̀',\n",
       "  'káðdɔ̀ɽðàt̪à',\n",
       "  'káŋú',\n",
       "  'kìcə̀lò',\n",
       "  'kìjɔ́',\n",
       "  'kícə̀lò',\n",
       "  'kúkù',\n",
       "  'kúkùŋù',\n",
       "  'kɔ̀ɾɔ́',\n",
       "  'kɛgiɲ',\n",
       "  'kɛgɛ',\n",
       "  'kɛ̀',\n",
       "  'kɛ̀gèɲɔ́',\n",
       "  'kɛ̀gìɲɔ́',\n",
       "  'kɛ̀ŋgìɲɔ́',\n",
       "  'l',\n",
       "  'lallivəlɛðir',\n",
       "  'laŋ',\n",
       "  'là',\n",
       "  'làlə́lvə̀lɛ̀ðɛ̀',\n",
       "  'làlə́lvə̀vɛ̀ðɔ̀',\n",
       "  'làrò',\n",
       "  'làvàrà',\n",
       "  'làŋə̀l',\n",
       "  'làŋə̄l',\n",
       "  'làɾò',\n",
       "  'lá',\n",
       "  'ládɔ̀ɽðàt̪à',\n",
       "  'lálló',\n",
       "  'lálə̀və̀lɛ̀ðír',\n",
       "  'lápɾí',\n",
       "  'lávándə́ŋé',\n",
       "  'láŋə́l',\n",
       "  'lâlló',\n",
       "  'lǎ',\n",
       "  'lǎlló',\n",
       "  'lèŋə̄l',\n",
       "  'lé',\n",
       "  'léɲál',\n",
       "  'léɲǎ',\n",
       "  'léɲǎl',\n",
       "  'lìcə̀lò',\n",
       "  'lìjɔ́',\n",
       "  'lícə̀lò',\n",
       "  'lídì',\n",
       "  'lídí',\n",
       "  'lídɔ̀',\n",
       "  'lídɔ́',\n",
       "  'lò',\n",
       "  'lòɽgà',\n",
       "  'ló',\n",
       "  'lós',\n",
       "  'lùbò',\n",
       "  'lùbó',\n",
       "  'lɔ̀bó',\n",
       "  'lɔ̀mɔ̀',\n",
       "  'lɔ̀ɽgà',\n",
       "  'lɔ́mɔ̀',\n",
       "  'lɔ́ɾɔ́',\n",
       "  'lə̀bò',\n",
       "  'lə̀bó',\n",
       "  'lə̀bórelated',\n",
       "  'lə̀vrà',\n",
       "  'lə̀və̀lɛ̀',\n",
       "  'lə̀və̀lɛ̀ðáɲàl',\n",
       "  'lə̀və̀lɛ̀ðáɲál',\n",
       "  'lə̀və̀lɛ̀ðáɲǎl',\n",
       "  'lə̀və̀lɛ̀ðɔ́l',\n",
       "  'lə̀və̀lɛ̀ðɜ̂llú',\n",
       "  'lɛv',\n",
       "  'lɜ́ú',\n",
       "  'máɽðɔ́',\n",
       "  'nàɾò',\n",
       "  'ná',\n",
       "  'ndrɛ̀ð',\n",
       "  'nd̪ɔ̀bà',\n",
       "  'nd̪ɔ̀bàgɛ̀',\n",
       "  'nícə̀lò',\n",
       "  'nɛ̀',\n",
       "  'nɜ́rù',\n",
       "  'nɜ́ɾù',\n",
       "  'nɜ́ɾú',\n",
       "  'òn',\n",
       "  't̪át̪ɛ̀',\n",
       "  't̪ɛ̀gìɲɔ́',\n",
       "  't̪ɛ̀ðìɲɔ́',\n",
       "  'ùnɛ̀ɾɛ̀',\n",
       "  'ùnɛ́ɾɛ́',\n",
       "  'ún',\n",
       "  'únɛ̀ɾɛ̀',\n",
       "  'və́lɛ̀',\n",
       "  'və́lɛ̀ð',\n",
       "  'və́lɛ̀ðà',\n",
       "  'və́lɛ̀ðàló',\n",
       "  'və́lɛ̀ðǎjó',\n",
       "  'və́lɛ̀ðǎlíjò',\n",
       "  'və́lɛ̀ðǎló',\n",
       "  'və́lɛ̀ðɔ́',\n",
       "  'və́lɛ̀ðɔ́ló',\n",
       "  'və́lɛ̀ðɛ̀',\n",
       "  'və́lɛ̀ðɛ̀ló',\n",
       "  'və́lɛ̀ðɛ̌',\n",
       "  'və́lɛ́',\n",
       "  'və́lɛ̂ð',\n",
       "  'və́lɛ̂ðà',\n",
       "  'və́lɛ̂ðàló',\n",
       "  'və́lɛ̂ðàlú',\n",
       "  'və́lɛ̂ðɔ́',\n",
       "  'və́lɛ̂ðɔ́lò',\n",
       "  'və́lɛ̂ðɔ́ló',\n",
       "  'və́lɛ̂ðɛ̀',\n",
       "  'və́lɛ̂ðɛ̀ló',\n",
       "  'və́lɛ̂ðɛ̀lú',\n",
       "  'və́lɛ̂ðɛ̌',\n",
       "  'ð',\n",
       "  'ðé',\n",
       "  'ðìcə̀lò',\n",
       "  'ðíbɔ́',\n",
       "  'ðî',\n",
       "  'ðə̀mbɾɔ́',\n",
       "  'ðə́máɽðá',\n",
       "  'ðə́píðɔ́',\n",
       "  'ðə̂',\n",
       "  'ðɛ̀',\n",
       "  'ðɛ́',\n",
       "  'ðɛ́ðî',\n",
       "  'ðɛ̂',\n",
       "  'ðɜ̂llú',\n",
       "  'ŋ',\n",
       "  'ŋg',\n",
       "  'ŋgánɔ́',\n",
       "  'ŋgánɔ́nà',\n",
       "  'ŋgèjɔ́',\n",
       "  'ŋgèɲɔ́',\n",
       "  'ŋgì',\n",
       "  'ŋgìɲɔ́',\n",
       "  'ŋgɛ́là',\n",
       "  'ŋicelo',\n",
       "  'ŋìcɔ́lɔ̀',\n",
       "  'ŋìcə̀lò',\n",
       "  'ŋícə̀lò',\n",
       "  'ŋòɽgà',\n",
       "  'ŋòɽòn',\n",
       "  'ŋòɽón',\n",
       "  'ŋɔ̀bò',\n",
       "  'ŋɔ̀bó',\n",
       "  'ŋə̀bò',\n",
       "  'ŋ̀cɔ́lɔ̀',\n",
       "  'ŋ̀cɛ́lɔ̀',\n",
       "  'ɔ',\n",
       "  'ɔɾɔ',\n",
       "  'ɔ́',\n",
       "  'ɔ́ndì',\n",
       "  'ɔ́ɟɔ̀',\n",
       "  'ɔ́ɟɔ́',\n",
       "  'ɔ́ɾɔ́',\n",
       "  'ɛ',\n",
       "  'ɛ̀',\n",
       "  'ɛ̀bɛ̀',\n",
       "  'ɛ̀ðɛ̀',\n",
       "  'ɛ̀ɾɛ̀ð',\n",
       "  'ɛ́là',\n",
       "  'ɛ́ðɛ̀',\n",
       "  'ɜ',\n",
       "  'ɜ́rú',\n",
       "  'ɜ́ɾù',\n",
       "  'ɜ́ɾú',\n",
       "  'ɜ̂l',\n",
       "  'ɜ̂lló',\n",
       "  'ɲá',\n",
       "  'ɲál',\n",
       "  'ɽ'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_lines = []\n",
    "tira_words = set()\n",
    "for filestem, paths in tqdm(stem2paths.items()):\n",
    "    eaf = Elan.Eaf(paths['eaf'])\n",
    "    for speaker in tqdm(speaker_tiers):\n",
    "        if speaker not in eaf.get_tier_names():\n",
    "            continue\n",
    "        for interval in eaf.get_annotation_data_for_tier(speaker):\n",
    "            value = interval[2]\n",
    "            words = remove_punct(value).split()\n",
    "            for word in words:\n",
    "                if is_tira_word(word):\n",
    "                    tira_words.add(word)\n",
    "len(tira_words), tira_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c530a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tira_dict_dir = r'C:\\projects\\malachor5\\data\\tira_mfa_dicts'\n",
    "os.makedirs(tira_dict_dir, exist_ok=True)\n",
    "tira_mfa_dict_path = os.path.join(tira_dict_dir, 'tira_mfa.dict')\n",
    "tira_arpa_dict_path = os.path.join(tira_dict_dir, 'tira_arpa.dict')\n",
    "\n",
    "\n",
    "mfa_dict_lines = []\n",
    "arpa_dict_lines = []\n",
    "\n",
    "for word in tira_words:\n",
    "    mfa_dict_lines.append(f\"{word}\\t{tira2mfa(word)}\\n\")\n",
    "    arpa_dict_lines.append(f\"{word}\\t{tira2arpabet(word)}\\n\")\n",
    "with open(tira_mfa_dict_path, 'w', encoding='utf8') as f:\n",
    "    f.writelines(mfa_dict_lines)\n",
    "with open(tira_arpa_dict_path, 'w', encoding='utf8') as f:\n",
    "    f.writelines(arpa_dict_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c5cf7",
   "metadata": {},
   "source": [
    "# Keyword lists\n",
    "Relatedly, create lists of keywords that are Tira words *and phrases* specific to each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9698e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 11.01it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.13it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20210312.eaf': 18,\n",
       "  'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20210913.eaf': 23,\n",
       "  'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20220327-2.eaf': 60},\n",
       " {'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20210312.eaf': {'a ló',\n",
       "   'àlɔ́',\n",
       "   'éɲá',\n",
       "   'jáŋə́l və́lɛ̀ðǎjó',\n",
       "   'jáŋə́l və́lɛ̀ðǎló',\n",
       "   'jɛ jə',\n",
       "   'laŋ',\n",
       "   'làŋə̀l və́lɛ̂ðɛ̀',\n",
       "   'làŋə̄l',\n",
       "   'lâlló və́lɛ̀ðɔ́',\n",
       "   'lǎ',\n",
       "   'léɲál və́lɛ̂ðà',\n",
       "   'léɲál və́lɛ̂ðɔ́ló nd̪ɔ̀bà',\n",
       "   'ló',\n",
       "   'lós',\n",
       "   'ùnɛ́ɾɛ́',\n",
       "   'ɜ̂l',\n",
       "   'ɲál'},\n",
       "  'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20210913.eaf': {'âɾò',\n",
       "   'cɔ́lɔ̀',\n",
       "   'íbí',\n",
       "   'lɔ́ɾɔ́',\n",
       "   'máɽðɔ́',\n",
       "   'ná',\n",
       "   'ðé',\n",
       "   'ðíbɔ́',\n",
       "   'ðî',\n",
       "   'ðî ðìcə̀lò',\n",
       "   'ðə̀mbɾɔ́',\n",
       "   'ðə́máɽðá',\n",
       "   'ðə̂',\n",
       "   'ðɛ̀',\n",
       "   'ŋìcɔ́lɔ̀',\n",
       "   'ŋòɽòn',\n",
       "   'ŋòɽón',\n",
       "   'ŋ̀cɔ́lɔ̀',\n",
       "   'ɔɾɔ',\n",
       "   'ɔ́ɾɔ́',\n",
       "   'ɛ̀bɛ̀',\n",
       "   'ɛ̀ɾɛ̀ð',\n",
       "   'ɜ́ɾú'},\n",
       "  'C:\\\\projects\\\\malachor5\\\\meta\\\\HH20220327-2.eaf': {'àn',\n",
       "   'àn kɛ̀gèɲɔ́ lídɔ̀',\n",
       "   'àn kɛ̀gìɲɔ́ lídɔ̀',\n",
       "   'àn ŋgèɲɔ́ àpɾì',\n",
       "   'àn ŋgì',\n",
       "   'àn ŋgìɲɔ́ lídɔ̀',\n",
       "   'àn ɔ́ndì',\n",
       "   'àn ɔ́ndì kágɛ̀',\n",
       "   'àn ɔ́ndì kágɛ̀ kúkù',\n",
       "   'àn ɔ́ndì kìjɔ́ àpɾí nɛ̀ ɛ̀ðɛ̀',\n",
       "   'àn ɔ́ɟɔ̀',\n",
       "   'àn ɔ́ɟɔ́',\n",
       "   'àn ɔ́ɟɔ́ kà',\n",
       "   'àpɾí',\n",
       "   'àpɾí ìjɔ́ lɔ́mɔ̀ nɛ̀ ɔ́ndì',\n",
       "   'àpɾí ìjɔ́ ɔ́ndì nɛ̀ ɛ̀ðɛ̀',\n",
       "   'ápɾí',\n",
       "   'cìcə̀lò',\n",
       "   'cùbó',\n",
       "   'cùbɔ̀',\n",
       "   'cə̀mú cícə̀lò',\n",
       "   'dɔ́ɽðàt̪à',\n",
       "   'giɲ',\n",
       "   'ìjɔ́ àpɾí',\n",
       "   'jìgèɲɔ́',\n",
       "   'kúkù kàŋú lídí',\n",
       "   'kúkù ŋgɛ́là',\n",
       "   'kɛ̀',\n",
       "   'kɛ̀gìɲɔ́',\n",
       "   'kɛ̀gìɲɔ́ lídɔ̀',\n",
       "   'kɛ̀ŋgìɲɔ́',\n",
       "   'làvàrà',\n",
       "   'lá',\n",
       "   'lá ápɾí',\n",
       "   'lìjɔ́',\n",
       "   'lìjɔ́ àpɾí nɛ̀ lɔ̀mɔ̀',\n",
       "   'lìjɔ́ àpɾí ɛ̀ðɛ̀ nɛ̀',\n",
       "   'lídí',\n",
       "   'lídɔ́',\n",
       "   'lòɽgà',\n",
       "   'lùbó',\n",
       "   'lɔ̀bó',\n",
       "   'lɔ̀mɔ̀',\n",
       "   'lɔ̀ɽgà',\n",
       "   'lə̀bò',\n",
       "   'lə̀bó',\n",
       "   'lə̀bórelated',\n",
       "   'lɜ́ú',\n",
       "   'nɛ̀',\n",
       "   'nɛ̀ lɔ̀mɔ̀',\n",
       "   'nɛ̀ ɛ̀ðɛ̀',\n",
       "   't̪át̪ɛ̀ kúkù ɛ́là àn t̪ɛ̀gìɲɔ́ lídɔ̀',\n",
       "   'ðə́píðɔ́',\n",
       "   'ŋgèɲɔ́',\n",
       "   'ŋgìɲɔ́',\n",
       "   'ŋòɽgà',\n",
       "   'ŋɔ̀bò',\n",
       "   'ŋə̀bò',\n",
       "   'ɔ́ɟɔ́',\n",
       "   'ɛ̀ðɛ̀'}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_per_file = {}\n",
    "for filestem, paths in tqdm(stem2paths.items()):\n",
    "    eaf = Elan.Eaf(paths['eaf'])\n",
    "    phrases_per_file[paths['eaf']]=set()\n",
    "    for speaker in tqdm(speaker_tiers):\n",
    "        if speaker not in eaf.get_tier_names():\n",
    "            continue\n",
    "        for interval in eaf.get_annotation_data_for_tier(speaker):\n",
    "            value = interval[2]\n",
    "            words = remove_punct(value).split()\n",
    "            current_phrase = ''\n",
    "            for word in words:\n",
    "                if not is_tira_word(word):\n",
    "                    if len(current_phrase)>3:\n",
    "                        phrases_per_file[paths['eaf']].add(current_phrase.strip())\n",
    "                    current_phrase = ''\n",
    "                elif current_phrase and word.strip() == current_phrase.split()[-1]:\n",
    "                    continue # don't add repeat words\n",
    "                else:\n",
    "                    current_phrase += word + ' '\n",
    "{k:len(v) for k,v in phrases_per_file.items()}, phrases_per_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1978f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dir = r'data\\keyword_lists'\n",
    "os.makedirs(keyword_dir, exist_ok=True)\n",
    "for eaf_path, phrases in phrases_per_file.items():\n",
    "    keyword_list_basename = os.path.basename(eaf_path.replace('.eaf', '-keywords.txt'))\n",
    "    keyword_list_path = os.path.join(keyword_dir, keyword_list_basename)\n",
    "    with open(keyword_list_path, 'w', encoding='utf8') as f:\n",
    "        f.write(\"\\n\".join(phrases))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
