{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/markjos/projects/malachor5')\n",
    "import sys\n",
    "sys.path.append('scripts')\n",
    "from longform import load_and_resample\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zulu_xml = 'data/SASOC/balanced_engzul.xml'\n",
    "xslt_path = 'data/SASOC/tabulate_corpus.xslt'\n",
    "dev_ids_path = 'data/SASOC/soapies_dev_and_test_set_utterance_ids/cs_engzul_balanced/transcriptions/engzul_dev_set_utterance_ids.txt'\n",
    "test_ids_path = 'data/SASOC/soapies_dev_and_test_set_utterance_ids/cs_engzul_balanced/transcriptions/engzul_tst_set_utterance_ids.txt'\n",
    "audio_path = 'data/SASOC/audio'\n",
    "cs_ds_path = 'data/hf-datasets/sasoc-cs'\n",
    "zul_ds_path = 'data/hf-datasets/sasoc-zul'\n",
    "eng_ds_path = 'data/hf-datasets/sasoc-eng'\n",
    "ds_paths = {\n",
    "    'codeswitched': cs_ds_path,\n",
    "    'zul': zul_ds_path,\n",
    "    'eng': eng_ds_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>transcription</th>\n",
       "      <th>lang_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>audio</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i had no idea so much preparation went into a ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>AKHONA</td>\n",
       "      <td>AKHONA_13-02-12_101.wav</td>\n",
       "      <td>3654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>then you should know that i will go very far t...</td>\n",
       "      <td>eng</td>\n",
       "      <td>AKHONA</td>\n",
       "      <td>AKHONA_13-02-12_149.wav</td>\n",
       "      <td>3597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>wenzani</td>\n",
       "      <td>zul</td>\n",
       "      <td>SENZO</td>\n",
       "      <td>SENZO_13-02-12_179.wav</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>yini indaba</td>\n",
       "      <td>zul</td>\n",
       "      <td>SENZO</td>\n",
       "      <td>SENZO_13-02-12_181.wav</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ufunani</td>\n",
       "      <td>zul</td>\n",
       "      <td>SENZO</td>\n",
       "      <td>SENZO_13-02-12_182.wav</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                      transcription lang_id  \\\n",
       "0      0  i had no idea so much preparation went into a ...     eng   \n",
       "1      0  then you should know that i will go very far t...     eng   \n",
       "2      0                                            wenzani     zul   \n",
       "3      0                                        yini indaba     zul   \n",
       "4      0                                            ufunani     zul   \n",
       "\n",
       "  speaker_id                    audio  duration  \n",
       "0     AKHONA  AKHONA_13-02-12_101.wav    3654.0  \n",
       "1     AKHONA  AKHONA_13-02-12_149.wav    3597.0  \n",
       "2      SENZO   SENZO_13-02-12_179.wav     428.0  \n",
       "3      SENZO   SENZO_13-02-12_181.wav     396.0  \n",
       "4      SENZO   SENZO_13-02-12_182.wav     344.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_xml(zulu_xml, stylesheet=xslt_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    13357\n",
       "test      2232\n",
       "dev        598\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(dev_ids_path) as f:\n",
    "    dev_ids = [x.strip() for x in f.readlines()]\n",
    "with open(test_ids_path) as f:\n",
    "    test_ids = [x.strip() for x in f.readlines()]\n",
    "is_dev = lambda s: s.removesuffix('.wav') in dev_ids\n",
    "is_test = lambda s: s.removesuffix('.wav') in test_ids\n",
    "get_split = lambda s: 'dev' if is_dev(s) else 'test' if is_test(s) else 'train'\n",
    "df['split'] = df['audio'].apply(get_split)\n",
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save deduped transcripts for training LM\n",
    "unique_sentences = df['transcription'].unique()\n",
    "zulu_txt_path = 'data/SASOC/balanced_engzul_train_deduped.txt'\n",
    "with open(zulu_txt_path, 'w') as f:\n",
    "    for sentence in unique_sentences:\n",
    "        f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id\n",
       "zul                                                    4362\n",
       "zul,eng                                                1239\n",
       "eng                                                    1225\n",
       "zul,eng,zul                                             789\n",
       "eng,zul                                                 738\n",
       "eng,zul,eng                                             318\n",
       "zul,eng,zul,eng                                         248\n",
       "eng,zul,eng,zul                                         151\n",
       "zul,eng,zul,eng,zul                                     119\n",
       "eng,zul,eng,zul,eng                                      59\n",
       "zul,eng,zul,eng,zul,eng                                  42\n",
       "eng,zul,eng,zul,eng,zul                                  24\n",
       "zul,eng,zul,eng,zul,eng,zul                              24\n",
       "eng,zul,eng,zul,eng,zul,eng                              12\n",
       "zul,eng,zul,eng,zul,eng,zul,eng                           6\n",
       "zul,eng,zul,eng,zul,eng,zul,eng,zul                       6\n",
       "eng,zul,eng,zul,eng,zul,eng,zul                           3\n",
       "zul,eng,zul,eng,zul,eng,zul,eng,zul,eng,zul               1\n",
       "eng,zul,eng,zul,eng,zul,eng,zul,eng                       1\n",
       "zul,eng,zul,eng,zul,eng,zul,eng,zul,eng,zul,eng,zul       1\n",
       "eng,zul,eng,zul,eng,zul,eng,zul,eng,zul,eng,zul           1\n",
       "zul,eng,zul,eng,zul,eng,zul,eng,zul,eng                   1\n",
       "eng,zul,eng,zul,eng,zul,eng,zul,eng,zul                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df=df.groupby('audio').agg({\n",
    "    'transcription': ' '.join,\n",
    "    'lang_id': ','.join,\n",
    "    'duration': 'sum',\n",
    "    'speaker_id': 'first',\n",
    "    'split': 'first',\n",
    "})\n",
    "grouped_df['lang_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.73778333333334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.loc[\n",
    "    grouped_df['lang_id']=='eng',\n",
    "    'duration'\n",
    "].sum()/60_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.76985"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.loc[\n",
    "    grouped_df['lang_id']=='zul',\n",
    "    'duration'\n",
    "].sum()/60_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430.43915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.loc[\n",
    "    grouped_df['lang_id'].str.contains(','),\n",
    "    'duration'\n",
    "].sum()/60_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>dev</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang_id_utt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>codeswitched</th>\n",
       "      <td>1326038.0</td>\n",
       "      <td>5823728.0</td>\n",
       "      <td>18676583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>837.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>5561832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zul</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5566191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split               dev       test       train\n",
       "lang_id_utt                                   \n",
       "codeswitched  1326038.0  5823728.0  18676583.0\n",
       "eng               837.0     1598.0   5561832.0\n",
       "zul                 NaN        NaN   5566191.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df['lang_id_utt']=grouped_df['lang_id']\n",
    "grouped_df.loc[\n",
    "    grouped_df['lang_id'].str.contains(','),\n",
    "    'lang_id_utt'\n",
    "] = 'codeswitched'\n",
    "pd.pivot_table(grouped_df, index='lang_id_utt', columns='split', values='duration', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>lang_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>split</th>\n",
       "      <th>lang_id_utt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEE_13-12-09_149.wav</th>\n",
       "      <td>whoa whoa</td>\n",
       "      <td>eng</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>BEE</td>\n",
       "      <td>test</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHOPPA_12-10-30_306.wav</th>\n",
       "      <td>do i look like i!m joking</td>\n",
       "      <td>eng</td>\n",
       "      <td>837.0</td>\n",
       "      <td>CHOPPA</td>\n",
       "      <td>dev</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     transcription lang_id  duration  \\\n",
       "audio                                                                  \n",
       "BEE_13-12-09_149.wav                     whoa whoa     eng    1598.0   \n",
       "CHOPPA_12-10-30_306.wav  do i look like i!m joking     eng     837.0   \n",
       "\n",
       "                        speaker_id split lang_id_utt  \n",
       "audio                                                 \n",
       "BEE_13-12-09_149.wav           BEE  test         eng  \n",
       "CHOPPA_12-10-30_306.wav     CHOPPA   dev         eng  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[(grouped_df['split']!='train')&(grouped_df['lang_id_utt']!='codeswitched')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving audio files for train split of codeswitched dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2793/2793 [00:00<00:00, 44620.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving audio files for dev split of codeswitched dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:00<00:00, 55787.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving audio files for test split of codeswitched dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [00:00<00:00, 40186.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving audio files for train split of zul dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4362/4362 [00:00<00:00, 73852.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving audio files for train split of eng dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1223/1223 [00:00<00:00, 15327.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for lang, ds_path in ds_paths.items():\n",
    "    os.makedirs(ds_path, exist_ok=True)\n",
    "    has_lang = grouped_df['lang_id_utt']==lang\n",
    "    lang_df = grouped_df[has_lang]\n",
    "    lang_df['file_name'] = lang_df['split'] + '/' + lang_df.index\n",
    "    lang_df.index.names = ['src_file']\n",
    "    lang_df.to_csv(\n",
    "        os.path.join(ds_path,'metadata.csv'),\n",
    "    )\n",
    "    for split in ['train', 'dev', 'test']:\n",
    "        if split != 'train' and lang != 'codeswitched':\n",
    "            continue\n",
    "        os.makedirs(os.path.join(ds_path,split), exist_ok=True)\n",
    "        has_split = lang_df['split']==split\n",
    "        split_df = lang_df[has_split]\n",
    "        print(f\"Saving audio files for {split} split of {lang} dataset\")\n",
    "        for audio in tqdm(split_df.index):\n",
    "            tgt_path = os.path.join(ds_path,split,audio)\n",
    "            src_path = os.path.join(audio_path,audio)\n",
    "            if not os.path.exists(tgt_path):\n",
    "                torchaudio.save(\n",
    "                    tgt_path,\n",
    "                    load_and_resample(src_path),\n",
    "                    16_000\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 2793/2793 [00:00<00:00, 95457.92it/s]\n",
      "Resolving data files: 100%|██████████| 224/224 [00:00<00:00, 451694.28it/s]\n",
      "Resolving data files: 100%|██████████| 767/767 [00:00<00:00, 449306.03it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2793/2793 [00:02<00:00, 1087.20 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 224/224 [00:00<00:00, 752.46 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 767/767 [00:00<00:00, 991.62 examples/s]\n",
      "Resolving data files: 100%|██████████| 4362/4362 [00:00<00:00, 28830.33it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4362/4362 [00:03<00:00, 1378.56 examples/s]\n",
      "Resolving data files: 100%|██████████| 1223/1223 [00:00<00:00, 442935.31it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1223/1223 [00:01<00:00, 687.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "for ds_path in ds_paths.values():\n",
    "    ds = load_dataset('audiofolder', data_dir=ds_path)\n",
    "    outpath = ds_path.replace('hf-datasets', 'pyarrow-datasets')\n",
    "    ds.save_to_disk(outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
